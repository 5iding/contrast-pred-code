{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch Training Jobs on Azure Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.exceptions import WorkspaceException\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Datastore\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.tensorboard import Tensorboard\n",
    "from azureml.train.hyperdrive import HyperDriveConfig\n",
    "from azureml.train.hyperdrive import GridParameterSampling\n",
    "from azureml.train.hyperdrive import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive import MedianStoppingPolicy\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_VMS = False\n",
    "USE_GPU = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing Workspace, using it.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ws = Workspace.create(name='replearn',\n",
    "                          location='eastus',\n",
    "                          resource_group='rg1',\n",
    "                          subscription_id='5fb52191-233d-4b0f-9713-de0e41784e6e')\n",
    "    ws.write_config()\n",
    "except WorkspaceException:\n",
    "    print('Found existing Workspace, using it.')\n",
    "    ws = Workspace.from_config(Path.cwd() / '.azureml' / 'config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIST_VMS:\n",
    "    print(AmlCompute.supported_vmsizes(workspace=ws))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Compute Target (Cluster)\n",
    "A persistent Azure Machine Learning Compute can be reused across jobs. The compute can be shared with other users in the workspace and is kept between jobs.  \n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, using it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Set cluster name\n",
    "cluster_name = \"NC6-cluster4\"\n",
    "vm_priority = 'dedicated'  # dedicated or lowpriority\n",
    "max_nodes = 4\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, using it.')\n",
    "except ComputeTargetException:\n",
    "    if USE_GPU:\n",
    "        vm_size = 'Standard_NC6s_v3'\n",
    "    else:\n",
    "        vm_size = 'Standard_DS4_v2'\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                           max_nodes=max_nodes,\n",
    "                                                           vm_priority=vm_priority,\n",
    "                                                           idle_seconds_before_scaledown=3600)\n",
    "    cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Datastore  \n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-access-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing training_data Datastore, using it.\n"
     ]
    }
   ],
   "source": [
    "datastores = ws.datastores\n",
    "if 'training_data' not in datastores.keys():\n",
    "    acct_key = 'fzVL5O3ybeVQ/eBeMzp5YqnmDUkFwhVJTWPaNezIuxAZWoduY79W7o3l3Zop3FN22txHCXl3UBkdaaM/9C+12Q=='\n",
    "    Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                            datastore_name='training_data', \n",
    "                                            container_name='asgdata',\n",
    "                                            account_name='asgdata', \n",
    "                                            account_key=acct_key,\n",
    "                                            create_if_not_exists=False)\n",
    "else:\n",
    "    print('Found existing training_data Datastore, using it.')\n",
    "ds = ws.datastores['training_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Experiment and Run  \n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-train-ml-models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `train_dir` and `val_dir` are path on container to training and val `*.tfr` files\n",
    "script_params = {\n",
    "    '--azure_ml': \"\",\n",
    "    '--train_dir': ds.path('Data/LibriSpeech/tfrecords/train-clean-100').as_download(),\n",
    "    '--val_dir': ds.path('Data/LibriSpeech/tfrecords/dev-clean').as_download()\n",
    "}\n",
    "\n",
    "tf_est = Estimator(source_directory=Path.cwd() / '..' / 'replearn',\n",
    "                   script_params=script_params,\n",
    "                   compute_target=cluster,\n",
    "                   use_gpu=USE_GPU,\n",
    "                   entry_script='train.py',\n",
    "                   pip_packages=['tensorflow-gpu==2.0.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'replearn'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mlworkspace.azure.ai/portal/subscriptions/5fb52191-233d-4b0f-9713-de0e41784e6e/resourceGroups/rg1/providers/Microsoft.MachineLearningServices/workspaces/replearn/experiments/replearn/runs/replearn_1573674050_838294b2\n",
      "RunId: replearn_1573674050_838294b2\n",
      "Web View: https://mlworkspace.azure.ai/portal/subscriptions/5fb52191-233d-4b0f-9713-de0e41784e6e/resourceGroups/rg1/providers/Microsoft.MachineLearningServices/workspaces/replearn/experiments/replearn/runs/replearn_1573674050_838294b2\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "2019/11/13 19:40:57 Downloading source code...\n",
      "2019/11/13 19:40:59 Finished downloading source code\n",
      "2019/11/13 19:40:59 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2019/11/13 19:40:59 Successfully set up Docker network: acb_default_network\n",
      "2019/11/13 19:40:59 Setting up Docker configuration...\n",
      "2019/11/13 19:41:00 Successfully set up Docker configuration\n",
      "2019/11/13 19:41:00 Logging in to registry: replearn798858f2.azurecr.io\n",
      "2019/11/13 19:41:02 Successfully logged into replearn798858f2.azurecr.io\n",
      "2019/11/13 19:41:02 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2019/11/13 19:41:02 Scanning for dependencies...\n",
      "2019/11/13 19:41:03 Successfully scanned dependencies\n",
      "2019/11/13 19:41:03 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  59.39kB\n",
      "\n",
      "Step 1/14 : FROM mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04@sha256:68177d37c98dcd91a576ff5c33786f5befa1073907ed50057049a7a173c61818\n",
      "sha256:68177d37c98dcd91a576ff5c33786f5befa1073907ed50057049a7a173c61818: Pulling from azureml/base-gpu\n",
      "f7277927d38a: Pulling fs layer\n",
      "8d3eac894db4: Pulling fs layer\n",
      "edf72af6d627: Pulling fs layer\n",
      "3e4f86211d23: Pulling fs layer\n",
      "d6e9603ff777: Pulling fs layer\n",
      "5cad422780e2: Pulling fs layer\n",
      "8130687c8acb: Pulling fs layer\n",
      "c11e9246d621: Pulling fs layer\n",
      "0dfae24cbbd9: Pulling fs layer\n",
      "0bb049a6d391: Pulling fs layer\n",
      "43dccd792c0b: Pulling fs layer\n",
      "8050d7a9e640: Pulling fs layer\n",
      "aeff47f124d9: Pulling fs layer\n",
      "a20c7d1a2dbd: Pulling fs layer\n",
      "b9010d25c0f8: Pulling fs layer\n",
      "aa53f80bd801: Pulling fs layer\n",
      "90baabccc7f2: Pulling fs layer\n",
      "3e4f86211d23: Waiting\n",
      "d6e9603ff777: Waiting\n",
      "43dccd792c0b: Waiting\n",
      "5cad422780e2: Waiting\n",
      "8050d7a9e640: Waiting\n",
      "8130687c8acb: Waiting\n",
      "aeff47f124d9: Waiting\n",
      "a20c7d1a2dbd: Waiting\n",
      "b9010d25c0f8: Waiting\n",
      "aa53f80bd801: Waiting\n",
      "90baabccc7f2: Waiting\n",
      "c11e9246d621: Waiting\n",
      "0dfae24cbbd9: Waiting\n",
      "0bb049a6d391: Waiting\n",
      "edf72af6d627: Download complete\n",
      "8d3eac894db4: Download complete\n",
      "3e4f86211d23: Verifying Checksum\n",
      "3e4f86211d23: Download complete\n",
      "d6e9603ff777: Verifying Checksum\n",
      "d6e9603ff777: Download complete\n",
      "5cad422780e2: Verifying Checksum\n",
      "5cad422780e2: Download complete\n",
      "8130687c8acb: Verifying Checksum\n",
      "8130687c8acb: Download complete\n",
      "f7277927d38a: Verifying Checksum\n",
      "f7277927d38a: Download complete\n",
      "0bb049a6d391: Verifying Checksum\n",
      "0bb049a6d391: Download complete\n",
      "c11e9246d621: Download complete\n",
      "43dccd792c0b: Verifying Checksum\n",
      "43dccd792c0b: Download complete\n",
      "8050d7a9e640: Verifying Checksum\n",
      "8050d7a9e640: Download complete\n",
      "aeff47f124d9: Verifying Checksum\n",
      "aeff47f124d9: Download complete\n",
      "a20c7d1a2dbd: Verifying Checksum\n",
      "a20c7d1a2dbd: Download complete\n",
      "aa53f80bd801: Verifying Checksum\n",
      "aa53f80bd801: Download complete\n",
      "90baabccc7f2: Verifying Checksum\n",
      "90baabccc7f2: Download complete\n",
      "b9010d25c0f8: Verifying Checksum\n",
      "b9010d25c0f8: Download complete\n",
      "0dfae24cbbd9: Verifying Checksum\n",
      "0dfae24cbbd9: Download complete\n",
      "f7277927d38a: Pull complete\n",
      "8d3eac894db4: Pull complete\n",
      "edf72af6d627: Pull complete\n",
      "3e4f86211d23: Pull complete\n"
     ]
    }
   ],
   "source": [
    "run = exp.submit(tf_est)\n",
    "print(run.get_portal_url())\n",
    "run.wait_for_completion(show_output=True)  # view stream of stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch TensorBoard Server  \n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-monitor-tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = Tensorboard([run])\n",
    "tb.start() # click on link and tensboard up-and-running with run training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close server when done\n",
    "tb.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning: Grid Search  \n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sampling = GridParameterSampling( {\n",
    "        \"batch_sz\": choice(32, 64, 128),\n",
    "        \"optimizer\": choice('adam', 'sgd_mom'),\n",
    "        \"lr\": choice('0.001', '0.01', '0.1')})\n",
    "\n",
    "hyperdrive_run_config = HyperDriveConfig(estimator=tf_est,\n",
    "                          hyperparameter_sampling=param_sampling, \n",
    "                          primary_metric_name=\"val_loss\",\n",
    "                          policy=MedianStoppingPolicy(evaluation_interval=5, delay_evaluation=5),\n",
    "                          primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n",
    "                          max_total_runs=100,\n",
    "                          max_concurrent_runs=max_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://mlworkspace.azure.ai/portal/subscriptions/5fb52191-233d-4b0f-9713-de0e41784e6e/resourceGroups/rg1/providers/Microsoft.MachineLearningServices/workspaces/replearn/experiments/hyperparam/runs/hyperparam_1570471202673140\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(ws, 'hyperparam')\n",
    "hyperdrive_run = experiment.submit(hyperdrive_run_config)\n",
    "print(hyperdrive_run.get_portal_url())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
